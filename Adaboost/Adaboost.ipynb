{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost\n",
    "\n",
    "Adaboost stands for adaptive boosting, it's a ensamble learning method. The output of the other learning algorithms ('weak learners') is combined into a weighted sum that represents the final output of the boosted classifier. AdaBoost is adaptive in the sense that subsequent weak learners are tweaked in favor of those instances misclassified by previous classifiers. AdaBoost is sensitive to noisy data and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First build a single decision stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):\n",
    "    retArray = ones((shape(dataMatrix)[0], 1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:, dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:, dimen] > threshVal] = -1.0\n",
    "    return retArray\n",
    "\n",
    "def buildStump(dataArr, classLabels, D):\n",
    "    dataMat = mat(dataArr)\n",
    "    labelMat = mat(classLabels).T\n",
    "    m,n = shape(dataMat)\n",
    "    numSteps = 10.0; bestStump = {}; bestClassEst = mat(zeros((m, 1)))\n",
    "    minError = inf\n",
    "    for i in range(n):\n",
    "        rangeMin = dataMat[:, i].min(); rangeMax = dataMat[:, i].max();\n",
    "        stepSize = (rangeMax - rangeMin) / numSteps\n",
    "        for j in range(-1, int(numSteps) + 1):\n",
    "            for inequal in ['lt', 'gt']:\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMat, i, threshVal, inequal)\n",
    "                errArr = mat(ones((m, 1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedErr = D.T*errArr\n",
    "                #print \"split: dim %d, thresh %.2f, thresh inequal %s, the weighted error is %.3f\" %\\\n",
    "                (i, threshVal, inequal, weightedErr)\n",
    "                if weightedErr < minError:\n",
    "                    minError = weightedErr\n",
    "                    bestClassEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClassEst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use adaboost to train decision stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr, classLabels, numIt = 40):\n",
    "    weekClassArr = []\n",
    "    m = shape(dataArr)[0]\n",
    "    D = mat(ones((m, 1)) / m)\n",
    "    aggClassEst = mat(zeros((m, 1)))\n",
    "    for i in range(numIt):\n",
    "        bestStump, error, classEst = buildStump(dataArr, classLabels, D)\n",
    "        #print \"D: \", D.T\n",
    "        alpha = float(0.5 * log((1.0 - error) / max(error, 1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "        weekClassArr.append(bestStump)\n",
    "        #print \"classEst: \", classEst.T\n",
    "        expon = multiply(-1*alpha*mat(classLabels).T, classEst)\n",
    "        D = multiply(D, exp(expon))\n",
    "        D = D/D.sum()\n",
    "        aggClassEst += alpha*classEst\n",
    "        #print \"aggClassEst: \", aggClassEst.T\n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T, ones((m, 1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        #print \"total error: \", errorRate, \"\\n\"\n",
    "        if errorRate == 0.0: break\n",
    "    return weekClassArr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adaClassify(datToClass, classifierArr):\n",
    "    dataMatrix = mat(datToClass)\n",
    "    m = shape(dataMatrix)[0]\n",
    "    aggClassEst = mat(zeros((m, 1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'],\\\n",
    "                                classifierArr[i]['thresh'],\\\n",
    "                                classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        #print aggClassEst\n",
    "    return sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))\n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = []\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat - 1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat, labelMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def errorRate(results, test_y):\n",
    "    len_test = len(test_y)\n",
    "    error_count = 0.0\n",
    "    label_pred = mat(results)\n",
    "    label_true = mat(test_y).T\n",
    "    arr_res = label_pred - label_true\n",
    "    for elem in arr_res:\n",
    "        error_count += abs(elem)\n",
    "    error_rate = error_count / len_test\n",
    "    print error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.29850746]]\n"
     ]
    }
   ],
   "source": [
    "trainfile = \"train.txt\"\n",
    "testfile = \"test.txt\"\n",
    "train_x, train_y = loadDataSet(trainfile)\n",
    "test_x, test_y = loadDataSet(testfile)\n",
    "classifier = adaBoostTrainDS(train_x, train_y, 10)\n",
    "results = adaClassify(test_x, classifier)\n",
    "errorRate(results, test_y)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
